{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dedb0e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad9632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_data():\n",
    "    data = pd.read_json('Outputs/Old/strengths.json', lines = True)\n",
    "\n",
    "    # Saving the filtered data to JSON file\n",
    "    data_path = \"Outputs/Old/old_model_data.json\"\n",
    "\n",
    "    data.to_json(data_path, orient='records', lines=True)\n",
    "    \n",
    "    return \"Outputs/Old/old_model_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51bf7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_small_exemplars(exemplars_list):\n",
    "    return any(exemplar < 0.0000000001 for exemplar in exemplars_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f6055e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_exemplars_and_adjust_frequency(row):\n",
    "    # Only proceed if frequency is greater than 1\n",
    "    if row['frequency'] > 1:\n",
    "        new_exemplars = [exemplar for exemplar in row['exemplar_strength'] if exemplar >= 0.0000000001]\n",
    "        if len(new_exemplars) < len(row['exemplar_strength']):\n",
    "            row['frequency'] = len(new_exemplars)  # Reduce frequency by if any exemplars are removed\n",
    "        row['exemplar_strength'] = new_exemplars\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7ee876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_model(runs):\n",
    "    for a in range(runs):\n",
    "        # Define mean dictionaries\n",
    "        means_1_6 = {}\n",
    "        means_7_12 = {}\n",
    "        \n",
    "        # Reset data path\n",
    "        pivoted_data_path = reset_data()\n",
    "\n",
    "        for i in range(10000):\n",
    "            # Read master data\n",
    "            df = pd.read_json(pivoted_data_path, orient='records', lines=True)\n",
    "\n",
    "            # Extract the 'words' dictionary from the DataFrame\n",
    "            words_data = df['word_key'].tolist()\n",
    "            frequencies = df['frequency'].astype(int).tolist()\n",
    "\n",
    "            # Picking a word based on its frequency\n",
    "            chosen_word = random.choices(words_data, weights=frequencies, k=1)[0]\n",
    "\n",
    "            # Extract exemplars for the chosen word\n",
    "            exemplars_list = df[df.word_key == chosen_word]['exemplars'].iloc[0]\n",
    "            \n",
    "            # Extract exemplar strengths for the chosen word\n",
    "            exemplar_strengths = df[df.word_key == chosen_word]['exemplar_strength'].iloc[0]\n",
    "\n",
    "            # Choose an exemplar weighted by exemplar strength\n",
    "            chosen_exemplar = random.choices(exemplars_list, weights=exemplar_strengths, k=1)[0]\n",
    "\n",
    "            # Add the chosen exemplar to the end of the exemplars list\n",
    "            exemplars_list.append(chosen_exemplar + 0.1)\n",
    "            \n",
    "            # Multiply all the exemplar strengths in the entire dataframe by 0.9\n",
    "            df['exemplar_strength'] = df['exemplar_strength'].apply(lambda x: [item * 0.9 for item in x])\n",
    "            exemplar_strengths = [item * 0.9 for item in exemplar_strengths]\n",
    "            \n",
    "            # Add an exemplar strength of 1 to the end of the exemplar strengths list \n",
    "            exemplar_strengths.append(1)\n",
    "\n",
    "            # Update the dataframe with the new exemplar list and exemplar strength list\n",
    "            df.at[df[df.word_key == chosen_word].index[0], 'exemplars'] = exemplars_list\n",
    "            df.at[df[df.word_key == chosen_word].index[0], 'exemplar_strength'] = exemplar_strengths\n",
    "            \n",
    "            # Check if any row has exemplars below the threshold\n",
    "            if df['exemplar_strength'].apply(contains_small_exemplars).any():\n",
    "                df = df.apply(remove_small_exemplars_and_adjust_frequency, axis=1)\n",
    "            \n",
    "            # Save the dataframe to JSON\n",
    "            df.to_json(pivoted_data_path, orient='records', lines=True)\n",
    "\n",
    "            # Save the mean of the exemplars\n",
    "            if int(df[df.word_key == chosen_word]['frequency']) < 7:\n",
    "                means_1_6[i] = np.mean(exemplars_list)\n",
    "            else:\n",
    "                means_7_12[i] = np.mean(exemplars_list)\n",
    "                \n",
    "        # Save the mean dictionaries as JSON files        \n",
    "        means_1_6_path = \"Outputs/Old/old_means_1_6_r\" + str(a+1) + \".json\"\n",
    "        means_7_12_path = \"Outputs/Old/old_means_7_12_r\" + str(a+1) + \".json\"\n",
    "\n",
    "        with open(means_1_6_path, 'w') as f:\n",
    "            json.dump(means_1_6, f)\n",
    "\n",
    "        with open(means_7_12_path, 'w') as f:\n",
    "            json.dump(means_7_12, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62b17f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
